{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df=pd.read_csv('af_water.csv')\n",
    "colname=df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 构建去噪自编码器模型\n",
    "def create_model(input_dim,encoding_dim):\n",
    "# input_dim = 9\n",
    "# encoding_dim = 5\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(7, activation='relu')(input_layer)\n",
    "    encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "    decoded = Dense(7, activation='relu')(encoded)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    encoder=Model(input_layer,encoded)\n",
    "\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')  #binary_crossentropy\n",
    "    return autoencoder,encoder\n",
    "\n",
    "# 添加高斯噪声\n",
    "def add_noise(x):\n",
    "    noise_factor = 0.1\n",
    "    x_noisy = x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x.shape)\n",
    "    return np.clip(x_noisy, 0., 1.)\n",
    "\n",
    "\n",
    "# 配置模型并进行训练\n",
    "def train_model(model,x_train,x_test,epochs=50,batch_size=128):\n",
    "    model.fit(add_noise(x_train), x_train, epochs=epochs, validation_data=(x_test, x_test),batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 提取深度特征\n",
    "# encoder = Model(input_layer, encoded)\n",
    "# encoded_input = Input(shape=(encoding_dim,))\n",
    "# decoder_layer = autoencoder.layers[-1]\n",
    "# decoder = Model(encoded_input, decoder_layer(encoded_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df_copy=df\n",
    "X=df.drop([\"Potability\"],axis=1)\n",
    "Y=df.Potability\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7,test_size=0.3,random_state=100,shuffle=False)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# Scaling the numeric variables of train dataset\n",
    "X_train[X_train.columns]= scaler.fit_transform(X_train[X_train.columns])\n",
    "# Scaling the numeric variables of test dataset\n",
    "X_test[X_test.columns]= scaler.transform(X_test[X_test.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 11ms/step - loss: 0.0195 - val_loss: 0.0187\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0177\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0170\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0166\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0162\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0160\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0158\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0157\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0156\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0155\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0154\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0152\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0144\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0142\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0139\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0138\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0137\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0134\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0134\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0133\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0133\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0133\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0132\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0132\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0132\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0132\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0132\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n"
     ]
    }
   ],
   "source": [
    "#创建网络\n",
    "autoencoder,encoder=create_model(9,5)\n",
    "train_model(autoencoder, X_train,X_test, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20928165569165005"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "X_pred = autoencoder.predict(X_test)\n",
    "r2 = r2_score(X_test, X_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=9.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#直接进行聚类\n",
    "\n",
    "x_encoder=encoder.predict(X_train)\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X_train)\n",
    "\n",
    "# 获取每个子模式所属的簇的标签\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  46.31 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "confusion_matrix = pd.crosstab(Y_train, labels, rownames=['Actual'], colnames=['Predicted'])\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "Accuracy_Decision_Tree=round((accuracy_score(Y_train, labels)*100),2)\n",
    "print('Accuracy: ',Accuracy_Decision_Tree,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import numpy as np\n",
    "\n",
    "# 定义VAE模型\n",
    "def build_vae(original_dim, intermediate_dim, latent_dim):\n",
    "    # 编码器\n",
    "    inputs = Input(shape=(original_dim,))\n",
    "    x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim)(x)\n",
    "    z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "    # 采样函数\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                                  mean=0., stddev=1.)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "    # 重参数化层\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    # 解码器\n",
    "    decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "    decoder_mean = Dense(original_dim, activation='linear')\n",
    "    h_decoded = decoder_h(z)\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "    # 定义VAE模型\n",
    "    vae = Model(inputs, x_decoded_mean)\n",
    "\n",
    "    # 定义损失函数\n",
    "    reconstruction_loss = original_dim * metrics.mean_squared_error(inputs, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "\n",
    "    return vae\n",
    "\n",
    "# 定义输入数据的维度和潜在空间维度\n",
    "original_dim = 9\n",
    "latent_dim = 3\n",
    "\n",
    "# 构建VAE模型\n",
    "vae = build_vae(original_dim, 6, latent_dim)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "\n",
    "# 生成虚拟数据\n",
    "x_train = np.random.rand(1000, original_dim)\n",
    "vae.fit(x_train, epochs=50, batch_size=32)\n",
    "\n",
    "# 生成虚拟数据\n",
    "z_sample = np.array([[-1.5, 0.5, 1.0]])\n",
    "x_decoded = vae.predict(z_sample)\n",
    "print(x_decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# 假设你的数据集已经加载到一个numpy数组中，叫做data\n",
    "data = np.random.rand(1000,9)\n",
    "\n",
    "# 定义GAN模型的参数\n",
    "latent_dim = 32 # 潜在空间的维度\n",
    "batch_size = 64 # 批次大小\n",
    "\n",
    "# 定义生成器网络，它将一个随机向量转换为一个9*1的向量\n",
    "def create_generator():\n",
    "    generator = keras.Sequential()\n",
    "    generator.add(layers.Dense(64, input_dim=latent_dim))\n",
    "    generator.add(layers.LeakyReLU(alpha=0.2))\n",
    "    generator.add(layers.Dense(9))\n",
    "    generator.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return generator\n",
    "\n",
    "# 定义判别器网络，它将一个9*1的向量判断为真实或者伪造\n",
    "def create_discriminator():\n",
    "    discriminator = keras.Sequential()\n",
    "    discriminator.add(layers.Dense(64, input_dim=9))\n",
    "    discriminator.add(layers.LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    discriminator.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return discriminator\n",
    "\n",
    "# 创建生成器和判别器对象\n",
    "generator = create_generator()\n",
    "discriminator = create_discriminator()\n",
    "\n",
    "# 定义GAN模型，它将生成器和判别器连接起来\n",
    "def create_gan(generator, discriminator):\n",
    "    gan = keras.Sequential()\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "    return gan\n",
    "\n",
    "# 创建GAN对象，并编译它\n",
    "gan = create_gan(generator, discriminator)\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "# 定义训练函数，它将在给定的迭代次数内训练GAN模型，并保存生成的向量到一个列表中\n",
    "def train_gan(gan, data, epochs):\n",
    "    # 获取生成器和判别器对象\n",
    "    generator, discriminator = gan.layers\n",
    "    \n",
    "    # 创建一个空列表来存储生成的向量\n",
    "    generated_vectors = []\n",
    "    \n",
    "    # 计算每个批次需要多少个样本，并创建一个索引数组来打乱数据集顺序 \n",
    "    samples_per_batch = int(data.shape[0]/batch_size)\n",
    "    index_array = np.arange(samples_per_batch) \n",
    "    \n",
    "     # 对每个迭代周期进行循环 \n",
    "    for epoch in range(epochs): \n",
    "         # 打乱索引数组 \n",
    "         # np.random.shuffle(index_array) \n",
    "        \n",
    "         # 对每个批次进行循环 \n",
    "         for i in range(0, batch_size): \n",
    "            \n",
    "             # 获取真实数据样本，并标记为1 \n",
    "            #  real_vectors = data[index_array[i : i + samples_per_batch]] \n",
    "             real_vectors = data[i:i+samples_per_batch] \n",
    "             real_labels = np.ones((samples_per_batch, 1)) \n",
    "            \n",
    "             # 从潜在空间中采样随机向量，并用生成器产生伪造数据样本，并标记为0 \n",
    "             random_vectors = np.random.normal(size=(samples_per_batch, latent_dim)) \n",
    "             fake_vectors = generator.predict(random_vectors) \n",
    "             fake_labels = np.zeros((samples_per_batch, 1)) \n",
    "            \n",
    "             # 将真实数据和伪造数据合并成一个批次，并打乱顺序 \n",
    "             vectors = np.concatenate([real_vectors, fake_vectors]) \n",
    "             labels = np.concatenate([real_labels, fake_labels]) \n",
    "         indices = np.arange(batch_size) \n",
    "         np.random.shuffle(indices) \n",
    "         vectors = vectors[indices] \n",
    "         labels = labels[indices] \n",
    "            \n",
    "            # 训练判别器网络，并计算损失值和准确率  \n",
    "         d_loss,d_accuarcy=discriminator.train_on_batch(vectors ,labels)    \n",
    "            # 从潜在空间中采样随机向量，并标记为1 \n",
    "         random_vectors = np.random.normal(size=(batch_size, latent_dim)) \n",
    "         gan_labels = np.ones((batch_size, 1)) \n",
    "            \n",
    "            # 训练GAN网络，并计算损失值 \n",
    "         g_loss = gan.train_on_batch(random_vectors, gan_labels) \n",
    "            \n",
    "            # 打印当前迭代周期和批次的损失值和准确率 \n",
    "         print(f\"Epoch {epoch}, Batch {i}, D Loss: {d_loss:.4f}, D Accuracy: {d_accuarcy:.4f}, G Loss: {g_loss:.4f}\") \n",
    "            \n",
    "        # 在每个迭代周期结束后，从潜在空间中采样一个随机向量，并用生成器产生一个伪造数据样本，并保存到列表中 \n",
    "         random_vector = np.random.normal(size=(1, latent_dim)) \n",
    "         generated_vector = generator.predict(random_vector) \n",
    "         generated_vectors.append(generated_vector) \n",
    "    \n",
    "    # 返回生成的向量列表 \n",
    "    return generated_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(gan, data, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "# 定义生成器函数\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(32, input_shape=(9,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(64, input_shape=(9,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(128, input_shape=(9,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(9, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# 定义判别器函数\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(32, input_shape=(9,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(64, input_shape=(9,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(128, input_shape=(9,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(128, input_shape=(9,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "# 定义GAN网络的训练函数\n",
    "def train_gan(generator, discriminator, dataset, epochs, batch_size, latent_dim):\n",
    "    for epoch in range(epochs):\n",
    "        # 初始化一个列表，用于存储每个批次的判别器损失值\n",
    "        d_losses = []\n",
    "        for batch in dataset.batch(batch_size):\n",
    "            # 训练判别器\n",
    "            real_samples = batch\n",
    "            fake_samples = generator(tf.random.normal(shape=(batch_size, latent_dim)))\n",
    "            X = tf.concat([real_samples, fake_samples], axis=0)\n",
    "            y = tf.constant([[1.0]] * batch_size + [[0.0]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            d_losses.append(d_loss)\n",
    "\n",
    "            # 训练生成器\n",
    "            noise = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "            y = tf.constant([[1.0]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, y)\n",
    "\n",
    "        # 计算判别器的平均损失值\n",
    "        d_loss_mean = np.mean(d_losses)\n",
    "\n",
    "        # 打印每一轮的损失值和生成器的输出\n",
    "        print(f\"Epoch {epoch+1}, D loss: {d_loss_mean:.4f}, G loss: {g_loss:.4f}\")\n",
    "        # print(\"Generated samples:\")\n",
    "        # print(fake_samples[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化生成器和判别器\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "generator.compile(loss='mse', optimizer='adam')\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# 组合生成器和判别器为一个GAN模型\n",
    "gan = tf.keras.Sequential([generator, discriminator])\n",
    "\n",
    "# 编译GAN模型\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# 加载样本数据\n",
    "samples = np.array(X_train)# 你的样本数据，应该是一个numpy数组或者pandas数据框\n",
    "\n",
    "# 计算需要补充的数量\n",
    "n_samples = len(samples)\n",
    "remainder = n_samples % batch_size\n",
    "padding = batch_size - remainder if remainder > 0 else 0\n",
    "\n",
    "# 用零进行补充\n",
    "samples = np.pad(samples, ((0, padding), (0, 0)), mode='constant')\n",
    "samples = samples.astype('float32') \n",
    "\n",
    "# 将样本数据转换成Dataset对象\n",
    "dataset = tf.data.Dataset.from_tensor_slices(samples)\n",
    "\n",
    "# 调用训练函数\n",
    "train_gan(generator, discriminator, dataset, epochs=100, batch_size=32, latent_dim=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "# 定义编码器函数\n",
    "def make_encoder_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128, input_shape=(9,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(32))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # 输出两个向量，分别表示均值和方差\n",
    "    model.add(layers.Dense(18))\n",
    "    return model\n",
    "\n",
    "# 定义解码器函数\n",
    "def make_decoder_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(32, input_shape=(9,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # 输出一个向量，表示重构后的数据\n",
    "    model.add(layers.Dense(9, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# 定义采样函数\n",
    "def sampling(mean_log_var):\n",
    "  # 将均值和方差分开\n",
    "  mean, log_var = tf.split(mean_log_var, num_or_size_splits=2, axis=1)\n",
    "  # 计算标准差\n",
    "  std = tf.exp(log_var * 0.5)\n",
    "  # 从标准正态分布中采样噪声\n",
    "  epsilon = tf.random.normal(shape=tf.shape(std))\n",
    "  # 返回采样结果\n",
    "  return mean + epsilon * std\n",
    "\n",
    "# 实例化编码器和解码器\n",
    "encoder = make_encoder_model()\n",
    "decoder = make_decoder_model()\n",
    "\n",
    "# 定义VAE模型类\n",
    "class VAE(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(VAE, self).__init__()\n",
    "  \n",
    "  def call(self, inputs):\n",
    "    # 编码输入数据得到均值和方差向量\n",
    "    mean_log_var = encoder(inputs)\n",
    "    # 对均值和方差进行采样得到潜在变量z\n",
    "    z = sampling(mean_log_var)\n",
    "    # 解码z得到重构后的输出数据\n",
    "    outputs = decoder(z)   \n",
    "    return outputs\n",
    "# 实例化VAE模型对象 \n",
    "vae = VAE()\n",
    "\n",
    "# 编译VAE模型对象 \n",
    "vae.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 加载样本数据并转换成float类型 \n",
    "# 加载样本数据\n",
    "samples = X_train# 你的样本数据，应该是一个numpy数组或者pandas数据框\n",
    "\n",
    "# 计算需要补充的数量\n",
    "n_samples = len(samples)\n",
    "remainder = n_samples % batch_size\n",
    "padding = batch_size - remainder if remainder > 0 else 0\n",
    "\n",
    "# 用零进行补充\n",
    "samples = np.pad(samples, ((0, padding), (0, 0)), mode='constant')\n",
    "samples = samples.astype('float32')\n",
    "\n",
    "# 训练VAE模型对象 \n",
    "vae.fit(samples, samples, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "#vae-wgan-gp\n",
    "import tensorflow as tf\n",
    "\n",
    "# Network\n",
    "latent_dim = 128\n",
    "dropout = 0.2\n",
    "leaky_relu_alpha = 0.2\n",
    "\n",
    "# CNN\n",
    "channels = 1\n",
    "filters = 32\n",
    "kernel_size = 3\n",
    "strides = 2\n",
    "padding = 'same'\n",
    "\n",
    "# Loss Coefficients\n",
    "kl_loss_coeff = 1\n",
    "perc_loss_coeff = 1\n",
    "\n",
    "class VAEWGANGP(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, discriminator, gp_weight=10.0):\n",
    "        super(VAEWGANGP, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.discriminator = discriminator\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, e_optimizer, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn, kl_loss_fn, perc_loss_fn, rec_loss_fn):\n",
    "        super(VAEWGANGP, self).compile()\n",
    "        self.e_optimizer = e_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        \n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        self.kl_loss_fn = kl_loss_fn\n",
    "        self.perc_loss_fn = perc_loss_fn\n",
    "        self.rec_loss_fn = rec_loss_fn\n",
    "        \n",
    "        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
    "        self.perc_loss_metric = tf.keras.metrics.Mean(name = 'perc_loss')\n",
    "        self.kl_loss_metric = tf.keras.metrics.Mean(name = 'kl_loss')\n",
    "        self.rec_loss_metric = tf.keras.metrics.Mean(name = 'rec_loss')\n",
    "        \n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            _, pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    \n",
    "    def call(self, data, training=False):\n",
    "    # This method exists only because Keras expects it to be able to use data_generator()\n",
    "    # your custom code when you call the model\n",
    "    # or just pass, you don't need this method\n",
    "    # for training\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric, self.perc_loss_metric, self.kl_loss_metric, self.rec_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        real_images = tf.cast(real_images, tf.float32)\n",
    "        # ===========================================================================\n",
    "        # Train Discriminator\n",
    "        # For WGAN, it is advised to train this multiple times before training generator\n",
    "        for _ in range(5):\n",
    "            _, _, z_encoder_output = self.encoder(real_images)\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_images = self.decoder(z_encoder_output, training = True)\n",
    "                _, logits_fake_images = self.discriminator(fake_images, training = True)\n",
    "                _, logits_real_images = self.discriminator(real_images, training = True)\n",
    "\n",
    "                d_cost = self.d_loss_fn(logits_real_images, logits_fake_images)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "            \n",
    "        # ===========================================================================\n",
    "        # Training Encoder\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_sigma, z_encoder_output = self.encoder(real_images, training = True)\n",
    "            kl_loss = self.kl_loss_fn(z_mean, z_log_sigma) * kl_loss_coeff\n",
    "            \n",
    "            fake_images = self.decoder(z_encoder_output, training = True)\n",
    "            fake_inter_activations, logits_fake = self.discriminator(fake_images, training = True)\n",
    "            real_inter_activations, logits_real = self.discriminator(real_images, training = True)\n",
    "            \n",
    "            perc_loss = self.perc_loss_fn(fake_inter_activations, real_inter_activations) * perc_loss_coeff\n",
    "\n",
    "            total_encoder_loss = kl_loss + perc_loss\n",
    "            \n",
    "        grads = tape.gradient(total_encoder_loss, self.encoder.trainable_weights)\n",
    "        self.e_optimizer.apply_gradients(zip(grads, self.encoder.trainable_weights))\n",
    "        \n",
    "        # ===========================================================================\n",
    "        # Train Decoder\n",
    "        _, _, z_encoder_output = self.encoder(real_images)\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.decoder(z_encoder_output)\n",
    "            fake_inter_activations, logits_fake = self.discriminator(fake_images, training = True)\n",
    "            real_inter_activations, _ = self.discriminator(real_images, training = True)\n",
    "            \n",
    "            g_loss = self.g_loss_fn(logits_fake, 0)\n",
    "            perc_loss = self.perc_loss_fn(fake_inter_activations, real_inter_activations)\n",
    "            \n",
    "            total_decoder_loss = g_loss + perc_loss * perc_loss_coeff\n",
    "\n",
    "        grads = tape.gradient(total_decoder_loss, self.decoder.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.decoder.trainable_weights))\n",
    "        \n",
    "        # Lasty, compute reconstruction loss for reporting purposes\n",
    "        rec_loss = self.rec_loss_fn(real_images, fake_images)\n",
    "        \n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        self.perc_loss_metric.update_state(perc_loss)\n",
    "        self.kl_loss_metric.update_state(kl_loss)\n",
    "        self.rec_loss_metric.update_state(rec_loss)\n",
    "        \n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "            \"perc_loss\": self.perc_loss_metric.result(),\n",
    "            \"kl_loss\": self.kl_loss_metric.result(),\n",
    "            \"rec_loss\": self.rec_loss_metric.result()\n",
    "        }\n",
    "\n",
    "class CustomKLLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"custom_kl_loss\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, z_mean, z_log_sigma):\n",
    "        kl_loss = - 0.5 * tf.keras.backend.mean(1 + z_log_sigma - tf.keras.backend.square(z_mean) - tf.keras.backend.exp(z_log_sigma))\n",
    "        return kl_loss\n",
    "    \n",
    "# L1 Norm loss\n",
    "class CustomL1NormLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"custom_L1_loss\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, z1, z2):\n",
    "        diff = z1 - z2\n",
    "        abs_ = tf.keras.backend.abs(diff)\n",
    "        return tf.keras.backend.sum(abs_)\n",
    "    \n",
    "class CustomDWLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"custom_d_wasserstein_loss\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, real_img, fake_img):\n",
    "        real_loss = tf.reduce_mean(real_img)\n",
    "        fake_loss = tf.reduce_mean(fake_img)\n",
    "        return fake_loss - real_loss\n",
    "    \n",
    "class CustomGWLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"custom_g_wasserstein_loss\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, fake_img, a):\n",
    "        return -tf.reduce_mean(fake_img)\n",
    "\n",
    "\n",
    "def vae_sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch_size = tf.shape(z_mean)[0]\n",
    "    latent_dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape = (batch_size, latent_dim), mean = 0, stddev = 0.1)\n",
    "    \n",
    "    return z_mean + tf.keras.backend.exp(z_log_sigma / 2) * epsilon\n",
    "\n",
    "def create_vaegan_networks(window_size, channels, latent_dim,\n",
    "                            filters, kernel_size, strides, padding, \n",
    "                            leaky_relu_alpha, dropout):\n",
    "\n",
    "    # Discriminator\n",
    "    # =========================================================================================\n",
    "    disc_input = tf.keras.layers.Input(shape=(window_size, 128, channels))\n",
    "\n",
    "    disc_conv = tf.keras.layers.Conv2D(filters, kernel_size, strides, padding)(disc_input)\n",
    "    disc_conv = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(disc_conv)\n",
    "\n",
    "    disc_conv = tf.keras.layers.Conv2D(filters * 2, kernel_size, strides, padding)(disc_conv)\n",
    "    disc_conv = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(disc_conv)\n",
    "\n",
    "    disc_conv = tf.keras.layers.Conv2D(filters * 4, kernel_size, strides, padding)(disc_conv)\n",
    "    disc_conv = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(disc_conv)\n",
    "\n",
    "    disc_conv = tf.keras.layers.Conv2D(filters * 8, kernel_size, strides, padding)(disc_conv)\n",
    "    disc_conv = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(disc_conv)\n",
    "\n",
    "    disc_conv = tf.keras.layers.Conv2D(filters * 16, kernel_size, strides, padding)(disc_conv)\n",
    "    disc_conv = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(disc_conv)\n",
    "\n",
    "    fc = tf.keras.layers.Flatten()(disc_conv)\n",
    "    fc = tf.keras.layers.Dense(filters * 2)(fc)\n",
    "    fc = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(fc)\n",
    "    fc = tf.keras.layers.Dropout(dropout)(fc)\n",
    "\n",
    "    disc_output = tf.keras.layers.Dense(1)(fc)\n",
    "\n",
    "    discriminator = tf.keras.models.Model(inputs = [disc_input], outputs = [disc_conv, disc_output])\n",
    "\n",
    "    # Encoder\n",
    "    # =========================================================================================\n",
    "    enc_filters = filters // 1\n",
    "    encoder_input = tf.keras.layers.Input(shape=(window_size, 128, channels))\n",
    "    enc_conv = tf.keras.layers.Conv2D(enc_filters, kernel_size, strides, padding)(encoder_input)\n",
    "    enc_conv = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(enc_conv)\n",
    "\n",
    "    enc_conv = tf.keras.layers.Conv2D(enc_filters * 2, kernel_size, strides, padding)(enc_conv)\n",
    "    enc_conv = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(enc_conv)\n",
    "\n",
    "    enc_conv = tf.keras.layers.Conv2D(enc_filters * 4, kernel_size, strides, padding)(enc_conv)\n",
    "    enc_conv = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(enc_conv)\n",
    "\n",
    "    enc_conv = tf.keras.layers.Conv2D(enc_filters * 8, kernel_size, strides, padding)(enc_conv)\n",
    "    enc_conv = tf.keras.layers.LeakyReLU(leaky_relu_alpha)(enc_conv)\n",
    "\n",
    "    enc_conv = tf.keras.layers.Conv2D(enc_filters * 16, kernel_size, strides, padding)(enc_conv)\n",
    "    enc_conv =  tf.keras.layers.LeakyReLU(leaky_relu_alpha)(enc_conv)\n",
    "\n",
    "    enc_conv = tf.keras.layers.AveragePooling2D()(enc_conv) # this reduces the num params by 2 to 3x\n",
    "    enc_conv = tf.keras.layers.Flatten()(enc_conv)\n",
    "    enc_conv = tf.keras.layers.Dropout(dropout)(enc_conv)\n",
    "\n",
    "    # Latent Space\n",
    "    z_mean = tf.keras.layers.Dense(latent_dim, activation = 'tanh')(enc_conv)\n",
    "    z_log_sigma = tf.keras.layers.Dense(latent_dim, activation = 'tanh')(enc_conv)\n",
    "    z_encoder_output = tf.keras.layers.Lambda(vae_sampling, output_shape = (latent_dim))([z_mean, z_log_sigma])\n",
    "    encoder = tf.keras.models.Model(inputs = encoder_input, outputs = [z_mean, z_log_sigma, z_encoder_output])\n",
    "\n",
    "    # Decoder\n",
    "    # =========================================================================================\n",
    "    dec_input = tf.keras.layers.Input(shape=(latent_dim))\n",
    "\n",
    "    dec_conv = tf.keras.layers.Dense(15 * 8 * 128)(dec_input)\n",
    "    dec_conv = tf.keras.layers.Reshape((15, 8, 128))(dec_conv)\n",
    "\n",
    "    dec_conv = tf.keras.layers.UpSampling2D()(dec_conv)\n",
    "    dec_conv = tf.keras.layers.Conv2D(filters * 4, kernel_size, 1, padding)(dec_conv)\n",
    "    dec_conv = tf.keras.layers.LayerNormalization()(dec_conv)\n",
    "    dec_conv = tf.keras.layers.ReLU()(dec_conv)\n",
    "\n",
    "    dec_conv = tf.keras.layers.UpSampling2D()(dec_conv)\n",
    "    dec_conv = tf.keras.layers.Conv2D(filters * 2, kernel_size, 1, padding)(dec_conv)\n",
    "    dec_conv = tf.keras.layers.LayerNormalization()(dec_conv)\n",
    "    dec_conv = tf.keras.layers.ReLU()(dec_conv)\n",
    "\n",
    "    dec_conv = tf.keras.layers.UpSampling2D()(dec_conv)\n",
    "    dec_conv = tf.keras.layers.Conv2D(filters * 1, kernel_size, 1, padding)(dec_conv)\n",
    "    dec_conv = tf.keras.layers.LayerNormalization()(dec_conv)\n",
    "    dec_conv = tf.keras.layers.ReLU()(dec_conv)\n",
    "\n",
    "    dec_conv = tf.keras.layers.UpSampling2D()(dec_conv)\n",
    "    dec_conv = tf.keras.layers.Conv2D(channels, kernel_size, 1, padding)(dec_conv)\n",
    "    dec_conv = tf.keras.layers.Activation('tanh')(dec_conv)\n",
    "\n",
    "    decoder = tf.keras.models.Model(inputs = [dec_input], outputs = [dec_conv])\n",
    "\n",
    "\n",
    "    return discriminator, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
